{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Fixer - Google Colab Worker\n",
    "\n",
    "This notebook processes books from the bookcli repository.\n",
    "\n",
    "**Instructions:**\n",
    "1. Get API keys from the providers listed below\n",
    "2. Enter your GitHub token when prompted\n",
    "3. Run all cells in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q requests httpx gitpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - ENTER YOUR KEYS HERE\n",
    "GITHUB_TOKEN = \"\"  # @param {type:\"string\"}\n",
    "GITHUB_REPO = \"ElliottSax/bookcli\"  # @param {type:\"string\"}\n",
    "WORKER_ID = 1  # @param {type:\"integer\"}\n",
    "TOTAL_WORKERS = 3  # @param {type:\"integer\"}\n",
    "\n",
    "# API Keys - Get these from the providers:\n",
    "# - DeepSeek: https://platform.deepseek.com/api_keys\n",
    "# - Groq: https://console.groq.com/keys\n",
    "# - OpenRouter: https://openrouter.ai/keys\n",
    "# - Together: https://api.together.xyz/settings/api-keys\n",
    "# - Fireworks: https://fireworks.ai/api-keys\n",
    "# - Cerebras: https://cloud.cerebras.ai/\n",
    "DEEPSEEK_API_KEY = \"\"  # @param {type:\"string\"}\n",
    "GROQ_API_KEY = \"\"  # @param {type:\"string\"}\n",
    "OPENROUTER_KEY = \"\"  # @param {type:\"string\"}\n",
    "TOGETHER_KEY = \"\"  # @param {type:\"string\"}\n",
    "FIREWORKS_API_KEY = \"\"  # @param {type:\"string\"}\n",
    "CEREBRAS_API_KEY = \"\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Clone repository\n",
    "if not GITHUB_TOKEN:\n",
    "    raise ValueError(\"Please set GITHUB_TOKEN in the cell above!\")\n",
    "\n",
    "repo_url = f\"https://{GITHUB_TOKEN}@github.com/{GITHUB_REPO}.git\"\n",
    "!rm -rf /content/bookcli\n",
    "!git clone --depth 1 {repo_url} /content/bookcli\n",
    "\n",
    "os.chdir(\"/content/bookcli\")\n",
    "print(f\"Cloned to /content/bookcli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration - only use APIs with keys\n",
    "APIS = []\n",
    "if GROQ_API_KEY:\n",
    "    APIS.append((\"Groq\", \"https://api.groq.com/openai/v1/chat/completions\", GROQ_API_KEY, \"llama-3.3-70b-versatile\"))\n",
    "if CEREBRAS_API_KEY:\n",
    "    APIS.append((\"Cerebras\", \"https://api.cerebras.ai/v1/chat/completions\", CEREBRAS_API_KEY, \"llama3.1-8b\"))\n",
    "if TOGETHER_KEY:\n",
    "    APIS.append((\"Together\", \"https://api.together.xyz/v1/chat/completions\", TOGETHER_KEY, \"meta-llama/Llama-3.3-70B-Instruct-Turbo\"))\n",
    "if FIREWORKS_API_KEY:\n",
    "    APIS.append((\"Fireworks\", \"https://api.fireworks.ai/inference/v1/chat/completions\", FIREWORKS_API_KEY, \"accounts/fireworks/models/llama-v3p3-70b-instruct\"))\n",
    "if OPENROUTER_KEY:\n",
    "    APIS.append((\"OpenRouter\", \"https://openrouter.ai/api/v1/chat/completions\", OPENROUTER_KEY, \"meta-llama/llama-3.2-3b-instruct:free\"))\n",
    "if DEEPSEEK_API_KEY:\n",
    "    APIS.append((\"DeepSeek\", \"https://api.deepseek.com/v1/chat/completions\", DEEPSEEK_API_KEY, \"deepseek-chat\"))\n",
    "\n",
    "if not APIS:\n",
    "    raise ValueError(\"Please set at least one API key!\")\n",
    "\n",
    "print(f\"Configured {len(APIS)} APIs: {[a[0] for a in APIS]}\")\n",
    "\n",
    "_api_idx = WORKER_ID - 1\n",
    "\n",
    "def call_api(prompt, max_tokens=4000):\n",
    "    global _api_idx\n",
    "    for i in range(len(APIS)):\n",
    "        idx = (_api_idx + i) % len(APIS)\n",
    "        name, url, key, model = APIS[idx]\n",
    "        try:\n",
    "            resp = requests.post(url,\n",
    "                headers={\"Authorization\": f\"Bearer {key}\", \"Content-Type\": \"application/json\"},\n",
    "                json={\"model\": model, \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                      \"max_tokens\": max_tokens, \"temperature\": 0.7},\n",
    "                timeout=120)\n",
    "            if resp.status_code == 200:\n",
    "                print(f\"  ✓ {name}\")\n",
    "                _api_idx = (idx + 1) % len(APIS)\n",
    "                return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "            elif resp.status_code == 429:\n",
    "                print(f\"  ⚠ {name} rate limited\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ {name}: {str(e)[:50]}\")\n",
    "    return None\n",
    "\n",
    "# Test API\n",
    "print(\"Testing APIs...\")\n",
    "result = call_api(\"Say 'API working' in 3 words\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Server-based mode (connect to book server via ngrok)\nSERVER_URL = \"\"  # @param {type:\"string\"} Enter your ngrok URL here\n\ndef expand_chapter(content, chapter_num=1):\n    \"\"\"Expand a short chapter to at least 2500 words.\"\"\"\n    words = len(content.split())\n    if words >= 2500:\n        return content, False\n\n    prompt = f\"\"\"Expand this chapter to at least 2500 words. Keep the same style, characters, and plot.\nDo not add author notes, commentary, or meta-text. Just write the expanded chapter.\n\nCHAPTER {chapter_num}:\n{content[:10000]}\n\nWrite the COMPLETE expanded chapter (at least 2500 words):\"\"\"\n\n    result = call_api(prompt, max_tokens=5000)\n    if result and len(result.split()) > words:\n        return result, True\n    return content, False\n\n\ndef fix_book_server(server_url, book_name):\n    \"\"\"Fix a book via server (with claim coordination).\"\"\"\n    worker_id = f\"colab_{WORKER_ID}\"\n    headers = {\"X-Worker-ID\": worker_id}\n\n    # Try to claim\n    try:\n        resp = requests.get(f\"{server_url}/claim/{book_name}\", headers=headers, timeout=10)\n        if resp.status_code != 200 or not resp.json().get(\"claimed\"):\n            print(f\"  Could not claim: {resp.json().get('reason', 'unknown')}\")\n            return False\n    except Exception as e:\n        print(f\"  Claim error: {e}\")\n        return False\n\n    try:\n        # Get book data\n        resp = requests.get(f\"{server_url}/book/{book_name}\", headers=headers, timeout=30)\n        data = resp.json()\n        chapters = data.get(\"chapters\", {})\n\n        updated_chapters = {}\n        for ch_name in sorted(chapters.keys()):\n            content = chapters[ch_name]\n            words = len(content.split())\n            if words < 2500:\n                print(f\"  Expanding {ch_name} ({words}w)\")\n                ch_num = int(ch_name.replace(\"chapter_\", \"\").replace(\".md\", \"\"))\n                expanded, changed = expand_chapter(content, ch_num)\n                if changed:\n                    updated_chapters[ch_name] = expanded\n                    print(f\"    → {len(expanded.split())}w\")\n                time.sleep(1)\n\n        # Update server\n        update = {\"quality_fixed\": True, \"fixed_by\": worker_id}\n        if updated_chapters:\n            update[\"chapters\"] = updated_chapters\n        requests.post(f\"{server_url}/book/{book_name}/update\",\n                     headers=headers, json=update, timeout=30)\n        print(f\"  ✓ Fixed {len(updated_chapters)} chapters\")\n        return True\n\n    except Exception as e:\n        print(f\"  Error: {e}\")\n        # Release claim on error\n        requests.get(f\"{server_url}/release/{book_name}\", headers=headers, timeout=5)\n        return False\n\n\ndef fix_book_local(book_dir):\n    \"\"\"Fix a single book locally (repo-based mode).\"\"\"\n    bible_path = book_dir / \"story_bible.json\"\n    if not bible_path.exists():\n        return False\n\n    with open(bible_path) as f:\n        bible = json.load(f)\n\n    if bible.get(\"quality_fixed\"):\n        return True\n\n    chapters = sorted(book_dir.glob(\"chapter_*.md\"))\n    if not chapters:\n        return False\n\n    print(f\"\\nFixing: {book_dir.name}\")\n    fixes = 0\n\n    for ch_path in chapters:\n        content = ch_path.read_text()\n        words = len(content.split())\n\n        if words < 2500:\n            print(f\"  Expanding {ch_path.name} ({words} words)\")\n            ch_num = int(ch_path.stem.split('_')[1])\n            expanded, changed = expand_chapter(content, ch_num)\n            if changed:\n                ch_path.write_text(expanded)\n                print(f\"    → {len(expanded.split())} words\")\n                fixes += 1\n\n    bible[\"quality_fixed\"] = True\n    bible[\"fixed_by\"] = f\"colab_worker_{WORKER_ID}\"\n    with open(bible_path, \"w\") as f:\n        json.dump(bible, f, indent=2)\n\n    print(f\"  ✓ Fixed {fixes} chapters\")\n    return True"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Choose mode: SERVER or LOCAL\nMODE = \"SERVER\"  # @param [\"SERVER\", \"LOCAL\"]\n\nif MODE == \"SERVER\" and SERVER_URL:\n    print(f\"Mode: SERVER ({SERVER_URL})\")\n    # Get books from server\n    try:\n        resp = requests.get(f\"{SERVER_URL}/status\", timeout=10)\n        status = resp.json()\n        print(f\"Server status: {status['fixed']}/{status['total']} fixed\")\n        \n        resp = requests.get(f\"{SERVER_URL}/books\", timeout=30)\n        my_books = resp.json().get(\"books\", [])\n        print(f\"Books available: {len(my_books)}\")\n    except Exception as e:\n        print(f\"Server error: {e}\")\n        my_books = []\nelse:\n    print(\"Mode: LOCAL (git-based)\")\n    fiction_dir = Path(\"/content/bookcli/output/fiction\")\n    all_books = sorted([d for d in fiction_dir.iterdir() if d.is_dir()])\n\n    unfixed = []\n    for book in all_books:\n        bible_path = book / \"story_bible.json\"\n        if bible_path.exists():\n            try:\n                with open(bible_path) as f:\n                    bible = json.load(f)\n                if not bible.get(\"quality_fixed\"):\n                    unfixed.append(book)\n            except json.JSONDecodeError:\n                unfixed.append(book)\n\n    my_books = [b for i, b in enumerate(unfixed) if i % TOTAL_WORKERS == (WORKER_ID - 1)]\n    print(f\"Total: {len(all_books)} | Unfixed: {len(unfixed)} | This worker: {len(my_books)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Process books\nimport random\n\nfixed_count = 0\nrandom.shuffle(my_books) if isinstance(my_books, list) and my_books else None\n\nfor i, book in enumerate(my_books[:50]):  # Limit to 50 books per run\n    book_name = book if isinstance(book, str) else book.name\n    print(f\"\\n[{i+1}/{min(len(my_books), 50)}] {book_name}\")\n    \n    try:\n        if MODE == \"SERVER\" and SERVER_URL:\n            if fix_book_server(SERVER_URL, book_name):\n                fixed_count += 1\n        else:\n            if fix_book_local(book):\n                fixed_count += 1\n    except Exception as e:\n        print(f\"  Error: {e}\")\n    \n    time.sleep(2)\n\nprint(f\"\\n\\n✓ Fixed {fixed_count} books\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit and push changes\n",
    "!git config user.name \"Colab Worker {WORKER_ID}\"\n",
    "!git config user.email \"colab@worker.local\"\n",
    "!git add output/fiction/\n",
    "!git diff --staged --stat\n",
    "\n",
    "# Commit if there are changes\n",
    "import subprocess\n",
    "result = subprocess.run([\"git\", \"diff\", \"--staged\", \"--quiet\"])\n",
    "if result.returncode != 0:\n",
    "    !git commit -m \"Fix books (Colab Worker {WORKER_ID})\"\n",
    "    !git push\n",
    "    print(\"Changes pushed!\")\n",
    "else:\n",
    "    print(\"No changes to commit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}