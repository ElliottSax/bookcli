{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Fixer - Google Colab Worker\n",
    "\n",
    "This notebook processes books from the bookcli repository.\n",
    "\n",
    "**Instructions:**\n",
    "1. Get API keys from the providers listed below\n",
    "2. Enter your GitHub token when prompted\n",
    "3. Run all cells in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q requests httpx gitpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - ENTER YOUR KEYS HERE\n",
    "GITHUB_TOKEN = \"\"  # @param {type:\"string\"}\n",
    "GITHUB_REPO = \"ElliottSax/bookcli\"  # @param {type:\"string\"}\n",
    "WORKER_ID = 1  # @param {type:\"integer\"}\n",
    "TOTAL_WORKERS = 3  # @param {type:\"integer\"}\n",
    "\n",
    "# API Keys - Get these from the providers:\n",
    "# - DeepSeek: https://platform.deepseek.com/api_keys\n",
    "# - Groq: https://console.groq.com/keys\n",
    "# - OpenRouter: https://openrouter.ai/keys\n",
    "# - Together: https://api.together.xyz/settings/api-keys\n",
    "# - Fireworks: https://fireworks.ai/api-keys\n",
    "# - Cerebras: https://cloud.cerebras.ai/\n",
    "DEEPSEEK_API_KEY = \"\"  # @param {type:\"string\"}\n",
    "GROQ_API_KEY = \"\"  # @param {type:\"string\"}\n",
    "OPENROUTER_KEY = \"\"  # @param {type:\"string\"}\n",
    "TOGETHER_KEY = \"\"  # @param {type:\"string\"}\n",
    "FIREWORKS_API_KEY = \"\"  # @param {type:\"string\"}\n",
    "CEREBRAS_API_KEY = \"\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Clone repository\n",
    "if not GITHUB_TOKEN:\n",
    "    raise ValueError(\"Please set GITHUB_TOKEN in the cell above!\")\n",
    "\n",
    "repo_url = f\"https://{GITHUB_TOKEN}@github.com/{GITHUB_REPO}.git\"\n",
    "!rm -rf /content/bookcli\n",
    "!git clone --depth 1 {repo_url} /content/bookcli\n",
    "\n",
    "os.chdir(\"/content/bookcli\")\n",
    "print(f\"Cloned to /content/bookcli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration - only use APIs with keys\n",
    "APIS = []\n",
    "if GROQ_API_KEY:\n",
    "    APIS.append((\"Groq\", \"https://api.groq.com/openai/v1/chat/completions\", GROQ_API_KEY, \"llama-3.3-70b-versatile\"))\n",
    "if CEREBRAS_API_KEY:\n",
    "    APIS.append((\"Cerebras\", \"https://api.cerebras.ai/v1/chat/completions\", CEREBRAS_API_KEY, \"llama3.1-8b\"))\n",
    "if TOGETHER_KEY:\n",
    "    APIS.append((\"Together\", \"https://api.together.xyz/v1/chat/completions\", TOGETHER_KEY, \"meta-llama/Llama-3.3-70B-Instruct-Turbo\"))\n",
    "if FIREWORKS_API_KEY:\n",
    "    APIS.append((\"Fireworks\", \"https://api.fireworks.ai/inference/v1/chat/completions\", FIREWORKS_API_KEY, \"accounts/fireworks/models/llama-v3p3-70b-instruct\"))\n",
    "if OPENROUTER_KEY:\n",
    "    APIS.append((\"OpenRouter\", \"https://openrouter.ai/api/v1/chat/completions\", OPENROUTER_KEY, \"meta-llama/llama-3.2-3b-instruct:free\"))\n",
    "if DEEPSEEK_API_KEY:\n",
    "    APIS.append((\"DeepSeek\", \"https://api.deepseek.com/v1/chat/completions\", DEEPSEEK_API_KEY, \"deepseek-chat\"))\n",
    "\n",
    "if not APIS:\n",
    "    raise ValueError(\"Please set at least one API key!\")\n",
    "\n",
    "print(f\"Configured {len(APIS)} APIs: {[a[0] for a in APIS]}\")\n",
    "\n",
    "_api_idx = WORKER_ID - 1\n",
    "\n",
    "def call_api(prompt, max_tokens=4000):\n",
    "    global _api_idx\n",
    "    for i in range(len(APIS)):\n",
    "        idx = (_api_idx + i) % len(APIS)\n",
    "        name, url, key, model = APIS[idx]\n",
    "        try:\n",
    "            resp = requests.post(url,\n",
    "                headers={\"Authorization\": f\"Bearer {key}\", \"Content-Type\": \"application/json\"},\n",
    "                json={\"model\": model, \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                      \"max_tokens\": max_tokens, \"temperature\": 0.7},\n",
    "                timeout=120)\n",
    "            if resp.status_code == 200:\n",
    "                print(f\"  ✓ {name}\")\n",
    "                _api_idx = (idx + 1) % len(APIS)\n",
    "                return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "            elif resp.status_code == 429:\n",
    "                print(f\"  ⚠ {name} rate limited\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ {name}: {str(e)[:50]}\")\n",
    "    return None\n",
    "\n",
    "# Test API\n",
    "print(\"Testing APIs...\")\n",
    "result = call_api(\"Say 'API working' in 3 words\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_chapter(content, title=\"\", chapter_num=1):\n",
    "    \"\"\"Expand a short chapter to at least 2500 words.\"\"\"\n",
    "    words = len(content.split())\n",
    "    if words >= 2500:\n",
    "        return content, False\n",
    "\n",
    "    prompt = f\"\"\"Expand this chapter to at least 2500 words. Keep the same style, characters, and plot.\n",
    "Do not add author notes, commentary, or meta-text. Just write the expanded chapter.\n",
    "\n",
    "CHAPTER {chapter_num}:\n",
    "{content[:10000]}\n",
    "\n",
    "Write the COMPLETE expanded chapter (at least 2500 words):\"\"\"\n",
    "\n",
    "    result = call_api(prompt, max_tokens=5000)\n",
    "    if result and len(result.split()) > words:\n",
    "        return result, True\n",
    "    return content, False\n",
    "\n",
    "\n",
    "def fix_book(book_dir):\n",
    "    \"\"\"Fix a single book.\"\"\"\n",
    "    bible_path = book_dir / \"story_bible.json\"\n",
    "    if not bible_path.exists():\n",
    "        return False\n",
    "\n",
    "    with open(bible_path) as f:\n",
    "        bible = json.load(f)\n",
    "\n",
    "    if bible.get(\"quality_fixed\"):\n",
    "        return True  # Already done\n",
    "\n",
    "    chapters = sorted(book_dir.glob(\"chapter_*.md\"))\n",
    "    if not chapters:\n",
    "        return False\n",
    "\n",
    "    print(f\"\\nFixing: {book_dir.name}\")\n",
    "    fixes = 0\n",
    "\n",
    "    for ch_path in chapters:\n",
    "        content = ch_path.read_text()\n",
    "        words = len(content.split())\n",
    "\n",
    "        if words < 2500:\n",
    "            print(f\"  Expanding {ch_path.name} ({words} words)\")\n",
    "            ch_num = int(ch_path.stem.split('_')[1])\n",
    "            expanded, changed = expand_chapter(content, bible.get('title', ''), ch_num)\n",
    "            if changed:\n",
    "                ch_path.write_text(expanded)\n",
    "                new_words = len(expanded.split())\n",
    "                print(f\"    Expanded to {new_words} words\")\n",
    "                fixes += 1\n",
    "\n",
    "    # Mark as fixed\n",
    "    bible[\"quality_fixed\"] = True\n",
    "    bible[\"fixed_by\"] = f\"colab_worker_{WORKER_ID}\"\n",
    "    with open(bible_path, \"w\") as f:\n",
    "        json.dump(bible, f, indent=2)\n",
    "\n",
    "    print(f\"  ✓ Fixed {fixes} chapters\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find books to fix\n",
    "fiction_dir = Path(\"/content/bookcli/output/fiction\")\n",
    "all_books = sorted([d for d in fiction_dir.iterdir() if d.is_dir()])\n",
    "\n",
    "# Filter to unfixed books\n",
    "unfixed = []\n",
    "for book in all_books:\n",
    "    bible_path = book / \"story_bible.json\"\n",
    "    if bible_path.exists():\n",
    "        try:\n",
    "            with open(bible_path) as f:\n",
    "                bible = json.load(f)\n",
    "            if not bible.get(\"quality_fixed\"):\n",
    "                unfixed.append(book)\n",
    "        except json.JSONDecodeError:\n",
    "            unfixed.append(book)\n",
    "\n",
    "# Distribute across workers\n",
    "my_books = [b for i, b in enumerate(unfixed) if i % TOTAL_WORKERS == (WORKER_ID - 1)]\n",
    "\n",
    "print(f\"Total books: {len(all_books)}\")\n",
    "print(f\"Unfixed: {len(unfixed)}\")\n",
    "print(f\"This worker ({WORKER_ID}/{TOTAL_WORKERS}): {len(my_books)} books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process books\n",
    "fixed_count = 0\n",
    "for i, book in enumerate(my_books):\n",
    "    print(f\"\\n[{i+1}/{len(my_books)}] {book.name}\")\n",
    "    try:\n",
    "        if fix_book(book):\n",
    "            fixed_count += 1\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "    \n",
    "    # Rate limiting\n",
    "    time.sleep(2)\n",
    "\n",
    "print(f\"\\n\\nFixed {fixed_count} books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit and push changes\n",
    "!git config user.name \"Colab Worker {WORKER_ID}\"\n",
    "!git config user.email \"colab@worker.local\"\n",
    "!git add output/fiction/\n",
    "!git diff --staged --stat\n",
    "\n",
    "# Commit if there are changes\n",
    "import subprocess\n",
    "result = subprocess.run([\"git\", \"diff\", \"--staged\", \"--quiet\"])\n",
    "if result.returncode != 0:\n",
    "    !git commit -m \"Fix books (Colab Worker {WORKER_ID})\"\n",
    "    !git push\n",
    "    print(\"Changes pushed!\")\n",
    "else:\n",
    "    print(\"No changes to commit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
