{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Fixer - Kaggle Worker\n",
    "\n",
    "This notebook processes books from the bookcli repository.\n",
    "\n",
    "**Setup:**\n",
    "1. Add your GitHub token as a Kaggle Secret named `GITHUB_TOKEN`\n",
    "2. Add API keys as secrets (DEEPSEEK_API_KEY, GROQ_API_KEY, etc.)\n",
    "3. Enable Internet access in notebook settings\n",
    "4. Run all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q requests httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to get tokens from Kaggle secrets\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    secrets = UserSecretsClient()\n",
    "    GITHUB_TOKEN = secrets.get_secret(\"GITHUB_TOKEN\")\n",
    "    DEEPSEEK_API_KEY = secrets.get_secret(\"DEEPSEEK_API_KEY\") or \"\"\n",
    "    GROQ_API_KEY = secrets.get_secret(\"GROQ_API_KEY\") or \"\"\n",
    "    OPENROUTER_KEY = secrets.get_secret(\"OPENROUTER_KEY\") or \"\"\n",
    "    TOGETHER_KEY = secrets.get_secret(\"TOGETHER_KEY\") or \"\"\n",
    "    FIREWORKS_API_KEY = secrets.get_secret(\"FIREWORKS_API_KEY\") or \"\"\n",
    "    CEREBRAS_API_KEY = secrets.get_secret(\"CEREBRAS_API_KEY\") or \"\"\n",
    "    print(\"Loaded secrets from Kaggle\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load Kaggle secrets: {e}\")\n",
    "    # Enter manually if secrets not available\n",
    "    GITHUB_TOKEN = \"\"\n",
    "    DEEPSEEK_API_KEY = \"\"\n",
    "    GROQ_API_KEY = \"\"\n",
    "    OPENROUTER_KEY = \"\"\n",
    "    TOGETHER_KEY = \"\"\n",
    "    FIREWORKS_API_KEY = \"\"\n",
    "    CEREBRAS_API_KEY = \"\"\n",
    "\n",
    "GITHUB_REPO = \"ElliottSax/bookcli\"\n",
    "WORKER_ID = 1  # Change this for different workers\n",
    "TOTAL_WORKERS = 3\n",
    "\n",
    "print(f\"GitHub Token: {'Set' if GITHUB_TOKEN else 'NOT SET'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "if not GITHUB_TOKEN:\n",
    "    raise ValueError(\"Please set GITHUB_TOKEN!\")\n",
    "\n",
    "repo_url = f\"https://{GITHUB_TOKEN}@github.com/{GITHUB_REPO}.git\"\n",
    "!rm -rf /kaggle/working/bookcli\n",
    "!git clone --depth 1 {repo_url} /kaggle/working/bookcli\n",
    "\n",
    "os.chdir(\"/kaggle/working/bookcli\")\n",
    "print(\"Repository cloned!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration - only use APIs with keys\n",
    "APIS = []\n",
    "if GROQ_API_KEY:\n",
    "    APIS.append((\"Groq\", \"https://api.groq.com/openai/v1/chat/completions\", GROQ_API_KEY, \"llama-3.3-70b-versatile\"))\n",
    "if CEREBRAS_API_KEY:\n",
    "    APIS.append((\"Cerebras\", \"https://api.cerebras.ai/v1/chat/completions\", CEREBRAS_API_KEY, \"llama3.1-8b\"))\n",
    "if TOGETHER_KEY:\n",
    "    APIS.append((\"Together\", \"https://api.together.xyz/v1/chat/completions\", TOGETHER_KEY, \"meta-llama/Llama-3.3-70B-Instruct-Turbo\"))\n",
    "if FIREWORKS_API_KEY:\n",
    "    APIS.append((\"Fireworks\", \"https://api.fireworks.ai/inference/v1/chat/completions\", FIREWORKS_API_KEY, \"accounts/fireworks/models/llama-v3p3-70b-instruct\"))\n",
    "if OPENROUTER_KEY:\n",
    "    APIS.append((\"OpenRouter\", \"https://openrouter.ai/api/v1/chat/completions\", OPENROUTER_KEY, \"meta-llama/llama-3.2-3b-instruct:free\"))\n",
    "if DEEPSEEK_API_KEY:\n",
    "    APIS.append((\"DeepSeek\", \"https://api.deepseek.com/v1/chat/completions\", DEEPSEEK_API_KEY, \"deepseek-chat\"))\n",
    "\n",
    "if not APIS:\n",
    "    raise ValueError(\"Please set at least one API key in Kaggle Secrets!\")\n",
    "\n",
    "print(f\"Configured {len(APIS)} APIs: {[a[0] for a in APIS]}\")\n",
    "\n",
    "_api_idx = WORKER_ID - 1\n",
    "\n",
    "def call_api(prompt, max_tokens=4000):\n",
    "    global _api_idx\n",
    "    for i in range(len(APIS)):\n",
    "        idx = (_api_idx + i) % len(APIS)\n",
    "        name, url, key, model = APIS[idx]\n",
    "        try:\n",
    "            resp = requests.post(url,\n",
    "                headers={\"Authorization\": f\"Bearer {key}\", \"Content-Type\": \"application/json\"},\n",
    "                json={\"model\": model, \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                      \"max_tokens\": max_tokens, \"temperature\": 0.7},\n",
    "                timeout=120)\n",
    "            if resp.status_code == 200:\n",
    "                print(f\"  ✓ {name}\")\n",
    "                _api_idx = (idx + 1) % len(APIS)\n",
    "                return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "            elif resp.status_code == 429:\n",
    "                print(f\"  ⚠ {name} rate limited\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ {name}: {str(e)[:50]}\")\n",
    "    return None\n",
    "\n",
    "# Test\n",
    "print(\"Testing APIs...\")\n",
    "result = call_api(\"Say 'working' in one word\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_chapter(content, title=\"\", chapter_num=1):\n",
    "    words = len(content.split())\n",
    "    if words >= 2500:\n",
    "        return content, False\n",
    "\n",
    "    prompt = f\"\"\"Expand this chapter to at least 2500 words. Keep the same style.\n",
    "\n",
    "CHAPTER {chapter_num}:\n",
    "{content[:10000]}\n",
    "\n",
    "Write the COMPLETE expanded chapter:\"\"\"\n",
    "\n",
    "    result = call_api(prompt, max_tokens=5000)\n",
    "    if result and len(result.split()) > words:\n",
    "        return result, True\n",
    "    return content, False\n",
    "\n",
    "\n",
    "def fix_book(book_dir):\n",
    "    bible_path = book_dir / \"story_bible.json\"\n",
    "    if not bible_path.exists():\n",
    "        return False\n",
    "\n",
    "    with open(bible_path) as f:\n",
    "        bible = json.load(f)\n",
    "\n",
    "    if bible.get(\"quality_fixed\"):\n",
    "        return True\n",
    "\n",
    "    chapters = sorted(book_dir.glob(\"chapter_*.md\"))\n",
    "    if not chapters:\n",
    "        return False\n",
    "\n",
    "    print(f\"\\nFixing: {book_dir.name}\")\n",
    "    fixes = 0\n",
    "\n",
    "    for ch_path in chapters:\n",
    "        content = ch_path.read_text()\n",
    "        words = len(content.split())\n",
    "\n",
    "        if words < 2500:\n",
    "            print(f\"  Expanding {ch_path.name} ({words}w)\")\n",
    "            ch_num = int(ch_path.stem.split('_')[1])\n",
    "            expanded, changed = expand_chapter(content, bible.get('title', ''), ch_num)\n",
    "            if changed:\n",
    "                ch_path.write_text(expanded)\n",
    "                print(f\"    → {len(expanded.split())}w\")\n",
    "                fixes += 1\n",
    "\n",
    "    bible[\"quality_fixed\"] = True\n",
    "    bible[\"fixed_by\"] = f\"kaggle_worker_{WORKER_ID}\"\n",
    "    with open(bible_path, \"w\") as f:\n",
    "        json.dump(bible, f, indent=2)\n",
    "\n",
    "    print(f\"  ✓ Fixed {fixes} chapters\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and distribute books\n",
    "fiction_dir = Path(\"/kaggle/working/bookcli/output/fiction\")\n",
    "all_books = sorted([d for d in fiction_dir.iterdir() if d.is_dir()])\n",
    "\n",
    "unfixed = []\n",
    "for book in all_books:\n",
    "    bible_path = book / \"story_bible.json\"\n",
    "    if bible_path.exists():\n",
    "        try:\n",
    "            with open(bible_path) as f:\n",
    "                bible = json.load(f)\n",
    "            if not bible.get(\"quality_fixed\"):\n",
    "                unfixed.append(book)\n",
    "        except:\n",
    "            unfixed.append(book)\n",
    "\n",
    "my_books = [b for i, b in enumerate(unfixed) if i % TOTAL_WORKERS == (WORKER_ID - 1)]\n",
    "\n",
    "print(f\"Total: {len(all_books)} | Unfixed: {len(unfixed)} | This worker: {len(my_books)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process books\n",
    "fixed = 0\n",
    "for i, book in enumerate(my_books):\n",
    "    print(f\"[{i+1}/{len(my_books)}] {book.name}\")\n",
    "    try:\n",
    "        if fix_book(book):\n",
    "            fixed += 1\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "    time.sleep(2)\n",
    "\n",
    "print(f\"\\nFixed {fixed} books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push changes\n",
    "!git config user.name \"Kaggle Worker\"\n",
    "!git config user.email \"kaggle@worker.local\"\n",
    "!git add output/fiction/\n",
    "!git diff --staged --stat\n",
    "\n",
    "import subprocess\n",
    "if subprocess.run([\"git\", \"diff\", \"--staged\", \"--quiet\"]).returncode != 0:\n",
    "    !git commit -m \"Fix books (Kaggle Worker {WORKER_ID})\"\n",
    "    !git push\n",
    "    print(\"Pushed!\")\n",
    "else:\n",
    "    print(\"No changes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
